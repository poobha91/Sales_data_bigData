# Sales_data_bigData
Cleaning, Explore and Visualize the data
Big data refers to extremely large and complex data sets that cannot be processed or analysed using traditional data processing methods. In recent years, the amount of data being generated has grown exponentially, and this has led to the emergence of big data technologies and tools that are designed to handle and analyse these large datasets.

Python is a popular programming language that is widely used for data analysis and manipulation, including in the context of big data. Python offers a range of libraries and tools such as pandas, NumPy, matplotlib, and more, that make it easy to work with large datasets and perform exploratory analysis. These libraries enable developers and data analysts to perform tasks such as data cleaning, aggregation, filtering, and visualization, all of which are critical in the context of big data analysis.

In this assignment, were provided with a sales dataset that contained data from different countries and cities. The task was to explore the data and identify any issues such as inconsistent column names, missing data, duplicate rows, untidy data, and unexpected data types. Once identified these issues, needed to clean the data and make it suitable for analysis.

To begin the data exploration process, first imported the necessary libraries such as pandas, NumPy, matplotlib, and seaborn. Then loaded the sales data into a panda DataFrame and used various pandas and NumPy functions to perform data cleaning and exploratory analysis. This included renaming columns with inconsistent names, dropping missing data, detecting, and identifying and removing duplicate rows.

After cleaning the data, then used matplotlib and seaborn to create various visualizations that helped us to understand the relationships between different columns such as cost, profit, and revenue. 

Overall, the process of exploring and cleaning the sales data required us to use various pandas and NumPy functions, as well as visualization libraries such as matplotlib and seaborn. By doing so, we were able to gain a deeper understanding of the dataset and prepare it for further analysis.
